{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "**What?** Features selection on the Pima Indian dataset\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "from numpy import mean, std\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    data = read_csv(filename, header=None)\n",
    "    # retrieve numpy array\n",
    "    dataset = data.values\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:, -1]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset('../DATASETS/pima-indians-diabetes.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model built using all features\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.56\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe would prefer to use a subset of features that achieves a classification accuracy \\nthat is as good or better than this.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We would prefer to use a subset of features that achieves a classification accuracy \n",
    "that is as good or better than this.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test, method):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=method, k=4)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model built using features selected by ANOVA F-test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.74\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, f_classif)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this case, we see that the model achieved an accuracy of about 78.74 percent, \\na lift in performance compared to the baseline that achieved 77.56 percent.\\nWHY is that happening?\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this case, we see that the model achieved an accuracy of about 78.74 percent, \n",
    "a lift in performance compared to the baseline that achieved 77.56 percent.\n",
    "WHY is that happening?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model built using features selected via mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.56\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(\n",
    "    X_train, y_train, X_test, mutual_info_classif)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this case, we can make no difference compared to the baseline model. \n",
    "This is interesting as we know the method chose a DIFFERENT four features\n",
    "compared to the previous method.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model built using an automatic feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "how do we know that is a good or best number of features to select? Instead of guessing, \n",
    "we can systematically test a range of different numbers of selected features and discover\n",
    "which results in the best performing model. This is called a grid search, where the k \n",
    "argument to the SelectKBest class can be tuned. It is good practice to evaluate model\n",
    "configurations on classification tasks using repeated stratified k-fold cross-validation.\n",
    "We will use three repeats of 10-fold cross-validation via the RepeatedStratifiedKFold class.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Accuracy: 0.770\n",
      "Best Config: {'anova__k': 7}\n"
     ]
    }
   ],
   "source": [
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the pipeline to evaluate\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# We have already seent that \"f_classif\" performed better than \"mutual_info_classif\"\n",
    "fs = SelectKBest(score_func=f_classif)\n",
    "pipeline = Pipeline(steps=[('anova',fs), ('lr', model)])\n",
    "# define the grid\n",
    "grid = dict()\n",
    "grid['anova__k'] = [i+1 for i in range(X.shape[1])]\n",
    "# define the grid search\n",
    "search = GridSearchCV(pipeline, grid, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize best\n",
    "print('Best Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Best Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We might want to see the relationship between the number of selected features and \n",
    "classification accuracy. m\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.748 (0.048)\n",
      ">2 0.756 (0.042)\n",
      ">3 0.761 (0.044)\n",
      ">4 0.759 (0.042)\n",
      ">5 0.770 (0.041)\n",
      ">6 0.766 (0.042)\n",
      ">7 0.770 (0.042)\n",
      ">8 0.769 (0.040)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1) \n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores    \n",
    "\n",
    "# define number of features to evaluate \n",
    "num_features = [i+1 for i in range(X.shape[1])]\n",
    "\n",
    "# enumerate each number of features\n",
    "results = list()\n",
    "for k in num_features:\n",
    "    # create pipeline\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    fs = SelectKBest(score_func=f_classif, k=k)\n",
    "    pipeline = Pipeline(steps=[('anova',fs), ('lr', model)]) # evaluate the model\n",
    "    scores = evaluate_model(pipeline)\n",
    "    results.append(scores)\n",
    "    # summarize the results\n",
    "    print('>%d %.3f (%.3f)' % (k, mean(scores), std(scores)))\n",
    "\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=num_features, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this case, it looks like selecting 5 or 7 features results in roughly the same accuracy.\n",
    "Box and whisker plots are created side-by-side showing the trend of increasing mean accuracy with \n",
    "the number of selected features to five features, after which it may become less stable. Selecting\n",
    "5 features might be an appropriate configuration in this case.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
