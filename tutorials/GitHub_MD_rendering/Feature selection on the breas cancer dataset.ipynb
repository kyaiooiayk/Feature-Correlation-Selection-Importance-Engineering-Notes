{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**What?** Feature selection on the breas cancer dataset\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What? Breast cancer categorical dataset\n",
    "\n",
    "The so-called Breast cancer dataset that has been widely studied as a machine learning dataset since the 1980s.\n",
    "The dataset classifies breast cancer patient data as either a recurrence or no recurrence of cancer. There are 286\n",
    "examples and 9 input variables. It is a binary classification problem. A naive model can achieve an accuracy of \n",
    "70 percent on this dataset. A good score is about 76 percent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import f_classif,chi2, mutual_info_classif,SelectPercentile,SelectFpr,SelectFdr, SelectFwe,GenericUnivariateSelect\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan of action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "As a first step, we will evaluate a LogisticRegression model using ALL the available features. Logistic regression \n",
    "is a good model for testing feature selection methods as it can perform better if irrelevant features are removed \n",
    "from the model. To recap:\n",
    "\n",
    "[1] Use all the feature\n",
    "[2] Remove some feature\n",
    "[3] Compare predictions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    data = read_csv(filename, header=None)\n",
    "    # retrieve numpy array\n",
    "    dataset = data.values\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:,-1]\n",
    "    # format all fields as string\n",
    "    X = X.astype(str)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset('../DATASETS/breast-cancer.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = oe.transform(X_train)\n",
    "    X_test_enc = oe.transform(X_test)\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model with -->>ALL<<-- the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model first\n",
    "model = LogisticRegression(solver = 'lbfgs')\n",
    "# Perform actual fitting\n",
    "model.fit(X_train_enc, y_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this case, we can see that the model achieves a classification accuracy of about 75 percent. We would prefer to\n",
    "use a subset of features that achieves a classification accuracy that is as good or better than this.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.79\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test_enc)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Under the hood the function ask you to use a score function and the number of feature you want to select. \n",
    "In this case we use chi2 with k=4 hence 4 features out of the 8 features available.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, X_test, scoreMethod):\n",
    "    print(\"Selected score_func:\", scoreMethod)\n",
    "    fs = SelectKBest(score_func = scoreMethod, k = 4)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected score_func: <function chi2 at 0x11dc1be50>\n"
     ]
    }
   ],
   "source": [
    "X_train_fs, X_test_fs = select_features(X_train_enc, y_train_enc, X_test_enc, chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model with -->>SOME<<-- the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the modela again \n",
    "model = LogisticRegression(solver = 'lbfgs')\n",
    "model.fit(X_train_fs, y_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this case, we see that the model achieved an accuracy of about 74 percent, a slight drop in performance. \n",
    "It is possible that some of the features removed are, in fact, adding value directly or in concert with the \n",
    "selected features. At this stage, we would probably prefer to use all of the input features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.74\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection using different score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "f_classif: ANOVA F-value between label/feature for classification tasks.mutual_info_classif Mutual \n",
    "information for a discrete target.\n",
    "\n",
    "chi2: Chi-squared stats of non-negative features for classification tasks. \n",
    "\n",
    "f_regression: F-value between label/feature for regression tasks.\n",
    "\n",
    "mutual_info_regression: Mutual information for a continuous target.\n",
    "\n",
    "SelectPercentile: Select features based on percentile of the highest scores.\n",
    "\n",
    "SelectFpr: Select features based on a false positive rate test.\n",
    "\n",
    "SelectFdr: Select features based on an estimated false discovery rate.\n",
    "\n",
    "SelectFwe: Select features based on family-wise error rate.\n",
    "\n",
    "GenericUnivariateSelect: Univariate feature selector with configurable mode.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runInLoop(scoreMethod):\n",
    "    # feature selection\n",
    "    X_train_fs, X_test_fs = select_features(\n",
    "    X_train_enc, y_train_enc, X_test_enc, scoreMethod)\n",
    "    # fit the model\n",
    "    #model1 = LogisticRegression(solver = 'lbfgs')\n",
    "    model1 = LogisticRegression()\n",
    "    model1.fit(X_train_fs, y_train_enc)\n",
    "    # evaluate the model\n",
    "    yhat = model1.predict(X_test_fs)\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test_enc, yhat)\n",
    "    print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected score_func: <function f_classif at 0x11dc1baf0>\n",
      "Accuracy: 74.74\n",
      "Selected score_func: <function chi2 at 0x11dc1be50>\n",
      "Accuracy: 74.74\n",
      "Selected score_func: <function mutual_info_classif at 0x11e2245e0>\n",
      "Accuracy: 70.53\n"
     ]
    }
   ],
   "source": [
    "scoreMethodsList = [f_classif,chi2, mutual_info_classif]\n",
    "for singleScoreMethod in scoreMethodsList:\n",
    "    runInLoop(singleScoreMethod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see a small lift in classification accuracy to 76 percent. To be sure that the effect is real, it would be a good idea to repeat each experiment multiple times and compare the mean performance. It may also be a good idea to explore using k-fold cross-validation instead of a simple train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
