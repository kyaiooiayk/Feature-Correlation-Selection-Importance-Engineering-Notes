{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What? Features selection for REGRESSION problem\n",
    "\n",
    "https://machinelearningmastery.com/feature-selection-for-regression-data/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "from matplotlib import pyplot\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_regression\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking python module versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 1.4.1\n",
      "numpy: 1.18.5\n",
      "matplotlib: 3.3.2\n",
      "pandas: 1.1.4\n",
      "statsmodels: 0.12.1\n",
      "sklearn: 0.23.2\n",
      "xgboostn: 1.2.1\n"
     ]
    }
   ],
   "source": [
    "def printPythonModuleVersion():    \n",
    "    \n",
    "    \"\"\"printPythonModuleVersion\n",
    "    Quickly list the python module versions\n",
    "    \"\"\"\n",
    "    \n",
    "    import scipy\n",
    "    print('scipy: %s' % scipy.__version__)\n",
    "    import numpy\n",
    "    print('numpy: %s' % numpy.__version__)    \n",
    "    import matplotlib\n",
    "    print('matplotlib: %s' % matplotlib.__version__)    \n",
    "    import pandas\n",
    "    print('pandas: %s' % pandas.__version__)\n",
    "    import statsmodels\n",
    "    print('statsmodels: %s' % statsmodels.__version__) \n",
    "    import sklearn\n",
    "    print('sklearn: %s' % sklearn.__version__)\n",
    "    import xgboost\n",
    "    print('xgboostn: %s' % xgboost.__version__)    \n",
    "\n",
    "printPythonModuleVersion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, X_test, chosenMethod):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func = chosenMethod, k = 'all') \n",
    "    # learn relationship from training data \n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fictitious REGRESSION dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The make regression() function from the scikit-learn library can be used to define a dataset.\n",
    "It provides control over the number of samples, number of input features, and, importantly, \n",
    "the number of relevant and irrelevant input features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.009419\n",
      "Feature 1: 1.018881\n",
      "Feature 2: 1.205187\n",
      "Feature 3: 0.000138\n",
      "Feature 4: 0.167511\n",
      "Feature 5: 5.985083\n",
      "Feature 6: 0.062405\n",
      "Feature 7: 1.455257\n",
      "Feature 8: 0.420384\n",
      "Feature 9: 101.392225\n",
      "Feature 10: 0.387091\n",
      "Feature 11: 1.581124\n",
      "Feature 12: 3.014463\n",
      "Feature 13: 0.232705\n",
      "Feature 14: 0.076281\n",
      "Feature 15: 4.299652\n",
      "Feature 16: 1.497530\n",
      "Feature 17: 0.261242\n",
      "Feature 18: 5.960005\n",
      "Feature 19: 0.523219\n",
      "Feature 20: 0.003365\n",
      "Feature 21: 0.024178\n",
      "Feature 22: 0.220958\n",
      "Feature 23: 0.576770\n",
      "Feature 24: 0.627198\n",
      "Feature 25: 0.350687\n",
      "Feature 26: 0.281877\n",
      "Feature 27: 0.584210\n",
      "Feature 28: 52.196337\n",
      "Feature 29: 0.046855\n",
      "Feature 30: 0.147323\n",
      "Feature 31: 0.368485\n",
      "Feature 32: 0.077631\n",
      "Feature 33: 0.698140\n",
      "Feature 34: 45.744046\n",
      "Feature 35: 2.047376\n",
      "Feature 36: 0.786270\n",
      "Feature 37: 0.996190\n",
      "Feature 38: 2.733533\n",
      "Feature 39: 63.957656\n",
      "Feature 40: 231.885540\n",
      "Feature 41: 1.372448\n",
      "Feature 42: 0.581860\n",
      "Feature 43: 1.072930\n",
      "Feature 44: 1.066976\n",
      "Feature 45: 0.344656\n",
      "Feature 46: 13.951551\n",
      "Feature 47: 3.575080\n",
      "Feature 48: 0.007299\n",
      "Feature 49: 0.004651\n",
      "Feature 50: 1.094585\n",
      "Feature 51: 0.241065\n",
      "Feature 52: 0.355137\n",
      "Feature 53: 0.020294\n",
      "Feature 54: 0.154567\n",
      "Feature 55: 2.592512\n",
      "Feature 56: 0.300175\n",
      "Feature 57: 0.357798\n",
      "Feature 58: 3.060090\n",
      "Feature 59: 0.890357\n",
      "Feature 60: 122.132164\n",
      "Feature 61: 2.029982\n",
      "Feature 62: 0.091551\n",
      "Feature 63: 1.081123\n",
      "Feature 64: 0.056041\n",
      "Feature 65: 2.930717\n",
      "Feature 66: 0.054886\n",
      "Feature 67: 1.332787\n",
      "Feature 68: 0.145579\n",
      "Feature 69: 0.986331\n",
      "Feature 70: 0.092661\n",
      "Feature 71: 0.083219\n",
      "Feature 72: 0.198847\n",
      "Feature 73: 2.065792\n",
      "Feature 74: 0.236594\n",
      "Feature 75: 0.512608\n",
      "Feature 76: 1.095650\n",
      "Feature 77: 0.015359\n",
      "Feature 78: 2.193730\n",
      "Feature 79: 1.574530\n",
      "Feature 80: 5.360863\n",
      "Feature 81: 0.041874\n",
      "Feature 82: 5.717705\n",
      "Feature 83: 0.436560\n",
      "Feature 84: 5.594438\n",
      "Feature 85: 0.000065\n",
      "Feature 86: 0.026748\n",
      "Feature 87: 0.408422\n",
      "Feature 88: 2.092557\n",
      "Feature 89: 9.568498\n",
      "Feature 90: 0.642445\n",
      "Feature 91: 0.065794\n",
      "Feature 92: 198.705931\n",
      "Feature 93: 0.073807\n",
      "Feature 94: 1.048605\n",
      "Feature 95: 0.004106\n",
      "Feature 96: 0.042110\n",
      "Feature 97: 0.034228\n",
      "Feature 98: 0.792433\n",
      "Feature 99: 0.015365\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, f_regression)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)): \n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "rcParams['font.size'] = 16\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A bar chart of the feature importance scores for each input feature is created. \n",
    "The plot clearly shows 8 to 10 features are a lot more important than the other\n",
    "features. We could set k = 10 When configuring the SelectKBest to select these \n",
    "top features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mutual information from the field of information theory is the application of \n",
    "information gain (typically used in the construction of decision trees) to \n",
    "feature selection. Mutual information is calculated between two variables and\n",
    "measures the reduction in uncertainty for one variable given a known value of\n",
    "the other variable. Mutual information is straightforward when considering the\n",
    "distribution of two discrete (categorical or ordinal) variables, such as categorical\n",
    "input and categorical output data. Nevertheless, it can be adapted for use with \n",
    "numerical input and output data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.045484\n",
      "Feature 1: 0.000000\n",
      "Feature 2: 0.000000\n",
      "Feature 3: 0.000000\n",
      "Feature 4: 0.024816\n",
      "Feature 5: 0.000000\n",
      "Feature 6: 0.022659\n",
      "Feature 7: 0.000000\n",
      "Feature 8: 0.000000\n",
      "Feature 9: 0.074320\n",
      "Feature 10: 0.000000\n",
      "Feature 11: 0.000000\n",
      "Feature 12: 0.000000\n",
      "Feature 13: 0.000000\n",
      "Feature 14: 0.020390\n",
      "Feature 15: 0.004307\n",
      "Feature 16: 0.000000\n",
      "Feature 17: 0.000000\n",
      "Feature 18: 0.016566\n",
      "Feature 19: 0.003688\n",
      "Feature 20: 0.007579\n",
      "Feature 21: 0.018640\n",
      "Feature 22: 0.025206\n",
      "Feature 23: 0.017967\n",
      "Feature 24: 0.069173\n",
      "Feature 25: 0.000000\n",
      "Feature 26: 0.022232\n",
      "Feature 27: 0.000000\n",
      "Feature 28: 0.007849\n",
      "Feature 29: 0.012849\n",
      "Feature 30: 0.017402\n",
      "Feature 31: 0.008083\n",
      "Feature 32: 0.047321\n",
      "Feature 33: 0.002829\n",
      "Feature 34: 0.028968\n",
      "Feature 35: 0.000000\n",
      "Feature 36: 0.071652\n",
      "Feature 37: 0.027969\n",
      "Feature 38: 0.000000\n",
      "Feature 39: 0.064796\n",
      "Feature 40: 0.137695\n",
      "Feature 41: 0.008732\n",
      "Feature 42: 0.003983\n",
      "Feature 43: 0.000000\n",
      "Feature 44: 0.009387\n",
      "Feature 45: 0.000000\n",
      "Feature 46: 0.038385\n",
      "Feature 47: 0.000000\n",
      "Feature 48: 0.000000\n",
      "Feature 49: 0.000000\n",
      "Feature 50: 0.000000\n",
      "Feature 51: 0.000000\n",
      "Feature 52: 0.000000\n",
      "Feature 53: 0.008130\n",
      "Feature 54: 0.041779\n",
      "Feature 55: 0.000000\n",
      "Feature 56: 0.000000\n",
      "Feature 57: 0.000000\n",
      "Feature 58: 0.031228\n",
      "Feature 59: 0.002689\n",
      "Feature 60: 0.146192\n",
      "Feature 61: 0.000000\n",
      "Feature 62: 0.000000\n",
      "Feature 63: 0.000000\n",
      "Feature 64: 0.018194\n",
      "Feature 65: 0.021368\n",
      "Feature 66: 0.046071\n",
      "Feature 67: 0.034707\n",
      "Feature 68: 0.033530\n",
      "Feature 69: 0.002262\n",
      "Feature 70: 0.018332\n",
      "Feature 71: 0.000000\n",
      "Feature 72: 0.000000\n",
      "Feature 73: 0.074876\n",
      "Feature 74: 0.000000\n",
      "Feature 75: 0.004429\n",
      "Feature 76: 0.002617\n",
      "Feature 77: 0.031354\n",
      "Feature 78: 0.000000\n",
      "Feature 79: 0.000000\n",
      "Feature 80: 0.000000\n",
      "Feature 81: 0.033931\n",
      "Feature 82: 0.010400\n",
      "Feature 83: 0.019373\n",
      "Feature 84: 0.000000\n",
      "Feature 85: 0.033191\n",
      "Feature 86: 0.000000\n",
      "Feature 87: 0.028745\n",
      "Feature 88: 0.000000\n",
      "Feature 89: 0.000000\n",
      "Feature 90: 0.000000\n",
      "Feature 91: 0.017698\n",
      "Feature 92: 0.129797\n",
      "Feature 93: 0.000000\n",
      "Feature 94: 0.002171\n",
      "Feature 95: 0.029995\n",
      "Feature 96: 0.000000\n",
      "Feature 97: 0.014428\n",
      "Feature 98: 0.000000\n",
      "Feature 99: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, mutual_info_regression)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)): \n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "rcParams['font.size'] = 16\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A bar chart of the feature importance scores for each input feature is created. Compared to the correlation \n",
    "feature selection method we can clearly see many more features scored as being relevant. This may be because\n",
    "of the statistical noise that we added to the dataset in its construction.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are many different techniques for scoring features and selecting features based on scores; how do you know\n",
    "which one to use? A robust approach is to evaluate models using different feature selection methods (and numbers\n",
    "of features) and select the method that results in a model with the best performance. In this section, we will \n",
    "evaluate a Linear Regression model with all features compared to a model built from features selected by \n",
    "correlation statistics and those features selected via mutual information. Linear regression is a good model \n",
    "for testing feature selection methods as it can perform better if irrelevant features are removed from the model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model built using ALL features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.086\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat) \n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying the select_feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test, chosenModel, featuresNo):\n",
    "    # configure to select a subset (ONLY 10) of features\n",
    "    fs = SelectKBest(score_func = chosenModel, k = featuresNo)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model built using correlation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.740\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, f_regression, 10)\n",
    "# fit the model\n",
    "model = LinearRegression() \n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this case, we see that the model achieved an error score of about 2.7, which is \n",
    "much larger than the baseline model that used all features and achieved an MAE of \n",
    "0.086. This suggests that although the method has a strong idea of what features \n",
    "to select, building a model from these features alone does not result in a more \n",
    "skillful model. This could be because features that are important to the target \n",
    "are being left out, meaning that the method is being deceived about what is important.\n",
    "\n",
    "\n",
    "-->>POSSIBLE SOLUTION<<--\n",
    "Letâ€™s go the other way and try to use the method to remove some irrelevant features \n",
    "rather than all irrelevant features. We can do this by setting the number of selected\n",
    "features to a much larger value, in this case, 88, hoping it can find and discard 12 \n",
    "of the 90 irrelevant features. The complete example is listed below\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.085\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, f_regression, 88)\n",
    "# fit the model\n",
    "model = LinearRegression() \n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat) \n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this case, we can see that removing some of the irrelevant features has resulted in \n",
    "a small lift in performance with an error of about 0.085 compared to the baseline that \n",
    "achieved an error of about 0.086.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model built using mutual information features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.084\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, mutual_info_regression, 88)\n",
    "# fit the model\n",
    "model = LinearRegression() \n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat) \n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this case, we can see a further reduction in error as compared to the correlation statistic, \n",
    "achieving a MAE of about 0.084 compared to 0.085 in the previous section.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the number of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: -0.082\n",
      "Best Config: {'sel__k': 81}\n",
      ">-1.100 with: {'sel__k': 80}\n",
      ">-0.082 with: {'sel__k': 81}\n",
      ">-0.082 with: {'sel__k': 82}\n",
      ">-0.082 with: {'sel__k': 83}\n",
      ">-0.082 with: {'sel__k': 84}\n",
      ">-0.082 with: {'sel__k': 85}\n",
      ">-0.082 with: {'sel__k': 86}\n",
      ">-0.082 with: {'sel__k': 87}\n",
      ">-0.082 with: {'sel__k': 88}\n",
      ">-0.083 with: {'sel__k': 89}\n",
      ">-0.083 with: {'sel__k': 90}\n",
      ">-0.083 with: {'sel__k': 91}\n",
      ">-0.083 with: {'sel__k': 92}\n",
      ">-0.083 with: {'sel__k': 93}\n",
      ">-0.083 with: {'sel__k': 94}\n",
      ">-0.083 with: {'sel__k': 95}\n",
      ">-0.083 with: {'sel__k': 96}\n",
      ">-0.083 with: {'sel__k': 97}\n",
      ">-0.083 with: {'sel__k': 98}\n",
      ">-0.083 with: {'sel__k': 99}\n",
      ">-0.083 with: {'sel__k': 100}\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1,random_state=1)\n",
    "# define the evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the pipeline to evaluate\n",
    "model = LinearRegression()\n",
    "fs = SelectKBest(score_func=mutual_info_regression)\n",
    "pipeline = Pipeline(steps=[('sel',fs), ('lr', model)])\n",
    "\n",
    "# define the grid\n",
    "grid = dict()\n",
    "grid['sel__k'] = [i for i in range(X.shape[1]-20, X.shape[1]+1)] \n",
    "\n",
    "# define the grid search\n",
    "search = GridSearchCV(pipeline, grid, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv) \n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize best\n",
    "print('Best MAE: %.3f' % results.best_score_) \n",
    "print('Best Config: %s' % results.best_params_) \n",
    "# summarize all\n",
    "means = results.cv_results_['mean_test_score'] \n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print('>%.3f with: %r' % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this case, we can see that the best number of selected features is 81, which achieves a MAE of about 0.082 \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
