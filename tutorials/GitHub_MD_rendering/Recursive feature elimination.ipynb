{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**What?** Recursive feature elimination (RFE)\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is recursive feature elimination?\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Fewer features can allow machine learning algorithms to run more efficiently (less space or time complexity) and be more effective. Some machine learning \n",
    "algorithms can be misled by irrelevant input features, resulting in worse predictive performance.\n",
    "\n",
    "- RFE works by searching for a subset of features by starting with all features in the training dataset and successfully removing features until the desired \n",
    "number remains. \n",
    "\n",
    "- This is achieved by fitting the given machine learning algorithm used in the core of the model, ranking features by importance, discarding the \n",
    "least important features, and re-fitting the model. \n",
    "\n",
    "- This process is repeated  until a specified number of features remains.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from numpy import mean, std\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.feature_selection import RFECV\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE for classification\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.886 (0.028)\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "model = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1) \n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# fit the model on all available data\n",
    "pipeline.fit(X, y)\n",
    "# make a prediction for one example\n",
    "data = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057,\n",
    "    -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
    "yhat = pipeline.predict(data) \n",
    "print('Predicted Class: %d' % (yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE for regression\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- We can use the make regression() function to create a synthetic regression problem with \n",
    "1,000 examples and 10 input features, five of which are important and five of which \n",
    "are redundant.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -27.246 (3.104)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=5) \n",
    "model = DecisionTreeRegressor()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# evaluate model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The scikit-learn library makes the MAE negative so that it is maximized instead of minimized. This means that negative MAE values closer to zero are better and a perfect model has a MAE of 0. \n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: -84.288\n"
     ]
    }
   ],
   "source": [
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=5) \n",
    "model = DecisionTreeRegressor()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# fit the model on all available data\n",
    "pipeline.fit(X, y)\n",
    "# make a prediction for one example\n",
    "data = [[-2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381,\n",
    "    0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n",
    "yhat = pipeline.predict(data) \n",
    "print('Predicted: %.3f' % (yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE hyperparameters - explore number of features\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- An important hyperparameter for the RFE algorithm is the number of features to select. \n",
    "- In the previous section, we used an arbitrary number of selected features, five, which matches the number of informative features in the synthetic dataset. \n",
    "- In practice, we  cannot know the best number of features to select with RFE; instead, it is good practice to test different values\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5,\n",
    "    random_state=1)\n",
    "    return X, y\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(2, 10):\n",
    "        rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i) \n",
    "        model = DecisionTreeClassifier()\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1) \n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1) \n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">2 0.715 (0.048)\n",
      ">3 0.821 (0.034)\n",
      ">4 0.875 (0.036)\n",
      ">5 0.885 (0.031)\n",
      ">6 0.886 (0.028)\n",
      ">7 0.888 (0.028)\n",
      ">8 0.890 (0.027)\n",
      ">9 0.887 (0.028)\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- We can see that performance improves as the number of features increase and perhaps peaks around 4-to-7 as we might expect, given that only five features are relevant \n",
    "to the target variable.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically select the number of features\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- It is also possible to automatically select the number of features chosen by RFE. \n",
    "\n",
    "- This can be achieved by performing cross-validation evaluation of different numbers of features as we did in the previous section and automatically selecting the number \n",
    "of features that resulted in the best mean score. \n",
    "\n",
    "- The RFECV class implements this. The RFECV is configured just like the RFE class regarding the choice of the algorithm \n",
    "that is wrapped. Additionally, the minimum number of features to be considered can be specified via the min features to select argument (defaults to 1) and we can also specify\n",
    "the type of cross-validation and scoring to use via the cv (defaults to 5) and scoring arguments (uses accuracy for classification).\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.884 (0.026)\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5,\n",
    "    random_state=1)\n",
    "# create pipeline\n",
    "rfe = RFECV(estimator=DecisionTreeClassifier()) \n",
    "model = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)]) \n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1) \n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- In this case, we can see the RFE that uses a decision tree and automatically selects a number of features and then fits a decision tree on the selected features achieves a \n",
    "classification accuracy of about 88.6 percent.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which features eere selected?\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected=False, Rank: 5\n",
      "Column: 1, Selected=False, Rank: 4\n",
      "Column: 2, Selected=True, Rank: 1\n",
      "Column: 3, Selected=True, Rank: 1\n",
      "Column: 4, Selected=True, Rank: 1\n",
      "Column: 5, Selected=False, Rank: 6\n",
      "Column: 6, Selected=True, Rank: 1\n",
      "Column: 7, Selected=False, Rank: 2\n",
      "Column: 8, Selected=True, Rank: 1\n",
      "Column: 9, Selected=False, Rank: 3\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# define RFE\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "# fit RFE\n",
    "rfe.fit(X, y)\n",
    "# summarize all features\n",
    "for i in range(X.shape[1]):\n",
    "    print('Column: %d, Selected=%s, Rank: %d' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Base Algorithm\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- There are many algorithms that can be used in the core RFE, as long as they provide some \n",
    "indication of variable importance. Most decision tree algorithms are likely to report the\n",
    "same general trends in feature importance, but this is not guaranteed. \n",
    "- It might be helpful to explore the use of different algorithms wrapped by RFE. \n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5,\n",
    "    random_state=1)\n",
    "    return X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # lr\n",
    "    rfe = RFE(estimator=LogisticRegression(), n_features_to_select=5)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['lr'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # perceptron\n",
    "    rfe = RFE(estimator=Perceptron(), n_features_to_select=5)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['per'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # cart\n",
    "    rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5) \n",
    "    model = DecisionTreeClassifier()\n",
    "    models['cart'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # rf\n",
    "    rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=5) \n",
    "    model = DecisionTreeClassifier()\n",
    "    models['rf'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # gbm\n",
    "    rfe = RFE(estimator=GradientBoostingClassifier(), n_features_to_select=5)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['gbm'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1) \n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1) \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.891 (0.032)\n",
      ">per 0.841 (0.036)\n",
      ">cart 0.884 (0.035)\n",
      ">rf 0.858 (0.039)\n",
      ">gbm 0.888 (0.031)\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- In this case, the results suggest that linear algorithms like logistic regression\n",
    "and the Perceptron might select better features more reliably than the chosen \n",
    "decision tree and ensemble of decision tree algorithms.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- A box and whisker plot is created for the distribution of accuracy scores for each \n",
    "configured wrapped algorithm. We can see the general trend of good performance with \n",
    "logistic regression, CART and perhaps GBM. \n",
    "- This highlights that even thought the actual\n",
    "model used to fit the chosen features is the same in each case, the model used within \n",
    "RFE can make an important difference to which features are selected and in turn the \n",
    "performance on the prediction problem.\n",
    "  \n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- https://machinelearningmastery.com/rfe-feature-selection-in-python/\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
