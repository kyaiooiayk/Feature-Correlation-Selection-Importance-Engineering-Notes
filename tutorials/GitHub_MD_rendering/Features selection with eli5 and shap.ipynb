{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to this python notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "What? Understaning feature importance\n",
    "\n",
    "The most important goal of this notebook is to show the extra feature of two libraries:\n",
    "[1] eli5\n",
    "[2] shap\n",
    "\n",
    "Reference: https://towardsdatascience.com/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e\n",
    "           https://github.com/erykml/medium_articles/blob/master/Machine%20Learning/feature_importance.ipynb\n",
    "           https://www.kdnuggets.com/2021/01/ultimate-scikit-learn-machine-learning-cheatsheet.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from rfpimp import plot_corr_heatmap\n",
    "from sklearn.metrics import r2_score\n",
    "from rfpimp import permutation_importances\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.base import clone\n",
    "from treeinterpreter import treeinterpreter as ti, utils\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "# Getting rid of the warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp_df(column_names, importances):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creating a pandas dataframe in ascending order\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'feature': column_names,\n",
    "                       'feature_importance': importances}) \\\n",
    "           .sort_values('feature_importance', ascending = False) \\\n",
    "           .reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "# plotting a feature importance dataframe (horizontal barchart)\n",
    "def var_imp_plot(imp_df, title):\n",
    "    imp_df.columns = ['feature', 'feature_importance']\n",
    "    sns.barplot(x = 'feature_importance', y = 'feature', data = imp_df, orient = 'h', color = 'royalblue') \\\n",
    "       .set_title(title, fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For this example, I will use the Boston house prices dataset (so a regression problem).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = boston.target\n",
    "X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark model [aka baseline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "random_state =42 -> to ensure results comparability\n",
    "oob_score = True -> so I could later use the out-of-bag error.\n",
    "\n",
    "There is some overfitting in the model, as it performs much worse on OOB sample and worse on the validation set.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "%time\n",
    "rf = RandomForestRegressor(n_estimators = 100,\n",
    "                           n_jobs = -1,\n",
    "                           oob_score = True,\n",
    "                           bootstrap = True,\n",
    "                           random_state = 42)\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R^2 Training Score: \", rf.score(X_train, y_train))\n",
    "print(\"OOB Score: \", rf.oob_score_)\n",
    "print(\"R^2 Validation Score: \", rf.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features importance vs. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature Importance is the process of finding the most important feature to a target. \n",
    "\n",
    "Through PCA, the feature that contains the most information can be found, but feature importance concerns a \n",
    "feature’s impact on the target. A change in an ‘important’ feature will have a large effect on the y-variable, \n",
    "whereas a change in an ‘unimportant’ feature will have little to no effect on the y-variable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Scikit-learn's feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In decision trees, every node is a condition how to split values in a single feature, so that similar values of\n",
    "dependent variable end up in the same set after the split. \n",
    "\n",
    "The condition is based on impurity, which in case of: \n",
    "    - Classification problems is Gini impurity / information gain (entropy), \n",
    "    - Regression trees its variance\n",
    "\n",
    "Thus, when training a tree we can compute how much each feature contributes to decreasing the weighted impurity. \n",
    "\n",
    "feature_importances_ in Scikit-Learn (for Random Forest) averages the decrease in impurity over trees.\n",
    "\n",
    "Pros:\n",
    "    - fast calculation\n",
    "    - easy to retrieve - one command\n",
    "Cons:\n",
    "     - biased approach, as it has a tendency to inflate the importance of continuous features or high-cardinality \n",
    "       categorical variables\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_imp = imp_df(X_train.columns, rf.feature_importances_)\n",
    "base_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15, 5\n",
    "rcParams['font.size'] = 17\n",
    "var_imp_plot(base_imp, 'Default feature importance (scikit-learn)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This approach directly measures feature importance by observing how random re-shuffling (thus preserving the\n",
    "distribution of the variable) of each predictor influences model performance.\n",
    "\n",
    "In other words, it is a method to evaluate how important a feature is. Several models are trained, each missing\n",
    "one column. The corresponding decrease in model accuracy as a result of the lack of data represents how important\n",
    "the column is to a model’s predictive power\n",
    "\n",
    "Pros:\n",
    "    - applicable to any model\n",
    "    - reasonably efficient\n",
    "    - reliable technique\n",
    "    - no need to retrain the model at each modification of the dataset\n",
    "\n",
    "Cons:\n",
    "    - more computationally expensive than default feature_importances\n",
    "    - permutation importance overestimates the importance of correlated predictors \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -->>rfpimp<<-- library based on permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "One more nice feature about rfpimp is that it contains functionalities for dealing with the issue of \n",
    "collinear features (that was the idea behind the Spearman's correlation matrix). \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(rf, X_train, y_train):\n",
    "    return r2_score(y_train, rf.predict(X_train))\n",
    "\n",
    "perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)\n",
    "perm_imp_rfpimp.reset_index(drop = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15, 5\n",
    "rcParams['font.size'] = 17\n",
    "var_imp_plot(perm_imp_rfpimp, 'Permutation feature importance (rfpimp)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -->>eli5<<-- library based on permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(rf, cv = None, refit = False, n_iter = 50).fit(X_train, y_train)\n",
    "perm_imp_eli5 = imp_df(X_train.columns, perm.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15, 5\n",
    "rcParams['font.size'] = 17\n",
    "var_imp_plot(perm_imp_eli5, 'Permutation feature importance (eli5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The results are very similar to the previous ones, even as these came from multiple reshuffles per column.\n",
    "The default importance DataFrame is not the most readable, as it does not contain variable names. This can\n",
    "be of course quite easily fixed. The nice thing is the standard error from all iterations of the reshuffling \n",
    "on each variable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(perm, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -->>shap<<-- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SHAP is another method of evaluating feature importance, borrowing from game theory principles in Blackjack \n",
    "to estimate how much value a player can contribute. Unlike permutation importance, SHapley Addative \n",
    "ExPlanations use a more formulaic and calculation-based method towards evaluating feature importance. \n",
    "SHAP requires a tree-based model (Decision Tree, Random Forest) and accommodates both regression and \n",
    "classification.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "rcParams['figure.figsize'] = 15, 5\n",
    "rcParams['font.size'] = 17\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, plot_type = \"bar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -->>PDP<<-- Partial Dependence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Partial dependence plots show how certain values of one feature influence a change in the target variable.\n",
    "Shaded areas represent confidence intervals. The change in the target value is seen on y-coordinate\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pdpbox import pdp, info_plots\n",
    "\n",
    "\n",
    "for singleFeatureName in X.columns.tolist():\n",
    "    pdp_dist = pdp.pdp_isolate(model=rf, \n",
    "                               dataset=X, \n",
    "                               model_features=X.columns.tolist(),\n",
    "                               feature=singleFeatureName)\n",
    "    pdp.pdp_plot(pdp_dist, singleFeatureName)\n",
    "    rcParams['figure.figsize'] = 15, 3\n",
    "    rcParams['font.size'] = 17\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contour PDPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Partial dependence plots can also take the form of contour plots, which compare not one isolated variable but \n",
    "the relationship between two isolated variables.\n",
    "Ref: https://github.com/SauceCat/PDPbox/issues/40\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns.tolist())\n",
    "\n",
    "\n",
    "compared_features = ['CRIM', 'ZN']\n",
    "inter = pdp.pdp_interact(model=rf, \n",
    "                          dataset=X, \n",
    "                          model_features=X.columns, \n",
    "                          features=compared_features)\n",
    "pdp.pdp_interact_plot(pdp_interact_out=inter,\n",
    "                      feature_names=compared_features,\n",
    "                      plot_type='contour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Column feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This approach is quite an intuitive one, as we investigate the importance of a feature by comparing a model \n",
    "with all features versus a model with this feature dropped for training.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_col_feat_imp(model, X_train, y_train, random_state = 42):\n",
    "    \n",
    "    # clone the model to have the exact same specification as the one initially trained\n",
    "    model_clone = clone(model)\n",
    "    # set random_state for comparability\n",
    "    model_clone.random_state = random_state\n",
    "    # training and scoring the benchmark model\n",
    "    model_clone.fit(X_train, y_train)\n",
    "    benchmark_score = model_clone.score(X_train, y_train)\n",
    "    print(\"Benchmark score [baseline]: \", benchmark_score)\n",
    "    # list for storing feature importances\n",
    "    deltaScore = []\n",
    "    \n",
    "    # iterating over all columns and storing feature importance (difference between benchmark and new model)\n",
    "    for col in X_train.columns:\n",
    "        print(\"Dropping feature name: \", col)\n",
    "        model_clone = clone(model)\n",
    "        model_clone.random_state = random_state\n",
    "        model_clone.fit(X_train.drop(col, axis = 1), y_train)\n",
    "        drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)\n",
    "        #print(drop_col_score)\n",
    "        #print(benchmark_score - drop_col_score)\n",
    "        deltaScore.append(benchmark_score - drop_col_score)        \n",
    "    \n",
    "    return deltaScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deltaScore = drop_col_feat_imp(rf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(X_train.columns):\n",
    "    print(feature, \" has delta score of: \", deltaScore[i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas dataframe which helps to sort via ascending order\n",
    "df2 = pd.DataFrame({'feature': X_train.columns,\n",
    "                   'deltaScore': deltaScore}) \\\n",
    "       .sort_values('deltaScore', ascending = False) \\\n",
    "       .reset_index(drop = True)\n",
    "    \n",
    "rcParams['figure.figsize'] = 15, 5\n",
    "rcParams['font.size'] = 17\n",
    "\n",
    "\n",
    "#df2.columns = ['feature', 'deltaScore']\n",
    "sns.barplot(x = 'deltaScore', y = 'feature', data = df2, orient = 'h', color = 'royalblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Negative importance in this case means that removing a given feature from the model actually improves the \n",
    "performance. What is weird is that the highest performance boost can be observed after removing DIS, which \n",
    "was the third most important variable in previous approaches.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation level feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the observation with the SMALLEST error, the main contributor was LSTAT and RM (which in previous cases \n",
    "turned out to be most important variables). \n",
    "In the highest error case, the HIGHEST contribution came from DIS variable, overcoming the same two variables\n",
    "that played the most important role in the first case.\n",
    "\n",
    "We'll use two libraries:\n",
    "    - treeinterpreter\n",
    "    - LIME\n",
    "    \n",
    "An discussion on the treeinterpreter vs LIME can be found here:\n",
    "https://stackoverflow.com/questions/48909418/lime-vs-treeinterpreter-for-interpreting-decision-tree/48975492\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## treeinterpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = [31, 85]\n",
    "selected_df = X_train.iloc[selected_rows,:].values\n",
    "prediction, bias, contributions = ti.predict(rf, selected_df)\n",
    "\n",
    "for i in range(len(selected_rows)):\n",
    "    print(\"Row\", selected_rows[i])\n",
    "    print(\"Prediction:\", prediction[i][0], 'Actual Value:', y_train[selected_rows[i]])\n",
    "    print(\"Bias (trainset mean)\", bias[i])\n",
    "    print(\"Feature contributions:\")\n",
    "    for c, feature in sorted(zip(contributions[i], \n",
    "                                 X_train.columns), \n",
    "                             key=lambda x: -abs(x[0])):\n",
    "        print(feature, round(c, 2))\n",
    "    print(\"-\"*20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To dive even deeper, we might also be interested in joined contribution of many variables\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1, bias1, contributions1 = ti.predict(rf, np.array([selected_df[0]]), joint_contribution=True)\n",
    "prediction2, bias2, contributions2 = ti.predict(rf, np.array([selected_df[1]]), joint_contribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_contributions1 = utils.aggregated_contribution(contributions1)\n",
    "aggregated_contributions2 = utils.aggregated_contribution(contributions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for k in set(aggregated_contributions1.keys()).union(\n",
    "              set(aggregated_contributions2.keys())):\n",
    "    res.append(([X_train.columns[index] for index in k] , \n",
    "               aggregated_contributions1.get(k, 0) - aggregated_contributions2.get(k, 0)))   \n",
    "         \n",
    "for lst, v in (sorted(res, key=lambda x:-abs(x[1])))[:10]:\n",
    "    print (lst, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The most of the difference between the best and worst predicted cases comes from the number of rooms (RM) feature, \n",
    "in conjunction with weighted distances to five Boston employment centres (DIS).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LIME (Local Interpretable Model-agnostic Explanations) is a technique explaining the predictions of any \n",
    "classifier/regressor in an interpretable and faithful manner. To do so, an explanation is obtained by \n",
    "locally approximating the selected model with an interpretable one (such as linear models with regularisation or decision trees). The interpretable models are trained on small perturbations (adding noise) of the original observation (row in case of tabular data), thus they only provide a good local approximation.\n",
    "\n",
    "Some drawbacks to be aware of:\n",
    "    - only linear models are used to approximate local behavior\n",
    "    - type of perturbations that need to be performed on the data to obtain correct explanations are often \n",
    "      use-case specific\n",
    "    - simple (default) perturbations are often not enough. In an ideal case, the modifications would be driven\n",
    "      by the variation that is observed in the dataset\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,\n",
    "                                                   mode = 'regression',\n",
    "                                                   feature_names = X_train.columns,\n",
    "                                                   categorical_features = [3], \n",
    "                                                   categorical_names = ['CHAS'], \n",
    "                                                   discretize_continuous = True)\n",
    "                                                   \n",
    "np.random.seed(42)\n",
    "exp = explainer.explain_instance(X_train.values[31], rf.predict, num_features = 5)\n",
    "exp.show_in_notebook(show_all=False) #only the features used in the explanation are displayed\n",
    "\n",
    "exp = explainer.explain_instance(X_train.values[85], rf.predict, num_features = 5)\n",
    "exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LIME interpretation agrees that for these two observations the most important features are RM and LSTAT, \n",
    "which was also indicated by previous approaches.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
